{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['filenames', 'batch_label', 'fine_labels', 'coarse_labels', 'data'])\n"
     ]
    }
   ],
   "source": [
    "# -----------------Have a look at the CIFAR-10 dataset-----------------\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "data = unpickle('data/unpacked/train')\n",
    "print(data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f3056b63fa0> <torch.utils.data.dataloader.DataLoader object at 0x7f3056b63ac0>\n"
     ]
    }
   ],
   "source": [
    "# ------------------Load data with data augmentation-------------------\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import default_collate\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3,4\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "CIFAR_PATH = \"data\"\n",
    "num_coarse_classes = 20\n",
    "num_fine_classes = 100\n",
    "\n",
    "# Calculated mean and standard deviation of image channels for normalization\n",
    "mean = [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]\n",
    "std = [0.2673342858792401, 0.2564384629170883, 0.27615047132568404]\n",
    "\n",
    "# Number of worker threads used for loading data\n",
    "num_workers = 0\n",
    "\n",
    "# CutMix augmentation\n",
    "cutmix = v2.CutMix(num_classes=100)\n",
    "\n",
    "# Define a custom collate function to apply CutMix\n",
    "def collate_fn(batch):\n",
    "    try:\n",
    "        return cutmix(*default_collate(batch))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Function to load the CIFAR-100 dataset\n",
    "def cifar100_dataset(batchsize):\n",
    "    # Define the data transformation for training data\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),  # Randomly crop the image with padding\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.RandomRotation(15),  # Randomly rotate the image\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "        transforms.Normalize(mean, std)  # Normalize the image using the predefined mean and std\n",
    "    ])\n",
    "    \n",
    "    # Define the data transformation for test data\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "        transforms.Normalize(mean, std)  # Normalize the image using the predefined mean and std\n",
    "    ])\n",
    "\n",
    "    # Load the training dataset\n",
    "    cifar100_training = torchvision.datasets.CIFAR100(\n",
    "        root=CIFAR_PATH,  # Root directory of the dataset\n",
    "        train=True,  # Load training data\n",
    "        download=True,  # Download the dataset if not available\n",
    "        transform=transform_train  # Apply the transformations\n",
    "    )\n",
    "    # Create a data loader for the training dataset\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        cifar100_training,  # The training dataset\n",
    "        batch_size=batchsize,  # Batch size\n",
    "        shuffle=True,  # Shuffle the data\n",
    "        num_workers=num_workers,  # Set number of workers to 0 for debugging\n",
    "        collate_fn=collate_fn,  # Apply CutMix augmentation\n",
    "        generator=torch.Generator(device=device), \n",
    "    )\n",
    "    \n",
    "    # Load the test dataset\n",
    "    cifar100_testing = torchvision.datasets.CIFAR100(\n",
    "        root=CIFAR_PATH,  # Root directory of the dataset\n",
    "        train=False,  # Load test data\n",
    "        download=True,  # Download the dataset if not available\n",
    "        transform=transform_test,  # Apply the transformations\n",
    "    )\n",
    "    # Create a data loader for the test dataset\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        cifar100_testing,  # The test dataset\n",
    "        batch_size=100,  # Batch size\n",
    "        shuffle=False,  # Do not shuffle the data\n",
    "        num_workers=num_workers,  # Set number of workers to 0 for debugging\n",
    "        generator=torch.Generator(device=device),  \n",
    "    )\n",
    "    \n",
    "    # Return the training and test data loaders\n",
    "    return trainloader, testloader\n",
    "\n",
    "trainloader, testloader = cifar100_dataset(batchsize=512*5)\n",
    "\n",
    "print(trainloader, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2560, 3, 32, 32])\n",
      "torch.Size([2560, 100])\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the dataloader\n",
    "for inputs, fine_labels in trainloader:\n",
    "    print(inputs.shape)  # Should print torch.Size([batch_size, 3, 32, 32])\n",
    "    print(fine_labels.shape)  # Should print torch.Size([batch_size, num_fine_classes])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for a test\n",
    "\n",
    "\n",
    "# from vit_pytorch import ViT\n",
    "# from torch import nn, optim\n",
    "\n",
    "# model = ViT(\n",
    "#     image_size = 32,\n",
    "#     patch_size = 4,\n",
    "#     num_classes = num_fine_classes,\n",
    "#     dim = 512,\n",
    "#     depth = 6,\n",
    "#     heads = 8,\n",
    "#     mlp_dim = 1024,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1,\n",
    "# ).to(device)\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 GPUs\n",
      "cuda\n",
      "Total parameters: 24.99M\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Use my implementation ------------------------\n",
    "from torch import nn, optim\n",
    "from myvit import VisionTransformer\n",
    "model = VisionTransformer(img_size=32, patch_size=4, d_model=48*16, num_heads=16, mlp_dim=48*8*3, num_layers=6, num_classes=100)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    devices = [0,1,2,3,4]\n",
    "    print(f\"Using {len(devices)} GPUs\")\n",
    "    model = nn.DataParallel(model, device_ids=devices)\n",
    "\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params_million = total_params / 10**6\n",
    "print(f\"Total parameters: {total_params_million:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/ViT')\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, schedulers=[], num_epochs=10, val_every_iter=False, start_epoch=0):\n",
    "    model.train()\n",
    "    global_step = 0\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        train_loader = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)  # tqdm progress bar\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # Record LR\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            writer.add_scalar('LR', current_lr, global_step)\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Add to tensorboard\n",
    "            writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "            global_step += 1\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            train_loader.set_postfix(loss=loss.item(), lr=current_lr)\n",
    "\n",
    "            # Val every iteration\n",
    "            if val_every_iter:\n",
    "                val_loss, accuracy = evaluate_model(model, testloader)\n",
    "                writer.add_scalar('Loss/val', val_loss, global_step)\n",
    "                writer.add_scalar('Accuracy/val', accuracy, global_step)\n",
    "\n",
    "        for scheduler in schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        loss_epoch = running_loss / len(trainloader)\n",
    "        if not val_every_iter:\n",
    "            val_loss, accuracy = evaluate_model(model, testloader)\n",
    "            writer.add_scalar('Loss/val', val_loss, global_step)\n",
    "            writer.add_scalar('Accuracy/val', accuracy, global_step)\n",
    "        # save model\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler1_state_dict': schedulers[0].state_dict(),\n",
    "                    'epoch': epoch\n",
    "                    }, f'weights/ViT/epoch{epoch+1}.pth')\n",
    "            print(\"*****************model saved*****************\\n\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_epoch}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            # Accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted_top5 = outputs.topk(5, dim=1, largest=True, sorted=True)\n",
    "            temp = predicted_top5 == labels.view(-1, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            correct_top5 += temp.sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        accuracy_top5 = correct_top5 / total\n",
    "    print(f\"Accuracy: {100 * accuracy:.2f}%, Accuracy(Top5): {100 * accuracy_top5:.2f}%\")\n",
    "    return val_loss/len(testloader), accuracy\n",
    "\n",
    "\n",
    "# Warm up and decrease of LR\n",
    "def lr_lambda(epoch):\n",
    "    warmup_epochs = 30\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        return 0.1 ** ((epoch - warmup_epochs) / 300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "num_epochs = 400\n",
    "\n",
    "if not os.path.exists('weights/ViT'):\n",
    "    os.makedirs('weights/ViT')\n",
    "torch.save({  # check how big the model is\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, f'weights/ViT/epoch{0}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and train the model\n",
    "\n",
    "# **********************\n",
    "# checkpoint = torch.load('weights/ViT/epoch1.pth', map_location=device)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler1_state_dict'])\n",
    "# start_epoch = checkpoint['epoch'] + 1\n",
    "#************************\n",
    "\n",
    "train_model(model, trainloader, criterion, optimizer, schedulers = [scheduler], num_epochs=num_epochs, start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.90%, Accuracy(Top5): 86.32%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.3963919854164124, 0.639)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and train the model\n",
    "\n",
    "# **********************\n",
    "checkpoint = torch.load('weights/ViT_patch_size4_d_model48*16_num_heads16_mlp_dim48*8*3_num_layers6/epoch200.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler1_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "#************************\n",
    "\n",
    "evaluate_model(model, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
